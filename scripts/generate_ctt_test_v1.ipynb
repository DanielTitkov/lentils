{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb058e7a",
   "metadata": {},
   "source": [
    "# CTT Generator v1.0.0\n",
    "\n",
    "Orrery allows for lots of flexibility in test creation, which makes presets rather wordy. \n",
    "For most project that flexibility is not needed. For example, in most tests all items have the same number of steps and each question has the same text and exactly one item. \n",
    "\n",
    "This utility scripts allows to generate Orrery's presets from much shorter templates. It is meant for manual use only and thus is not secure at all. It doesn't have any validation or error management. This is intentional though, because if generation is fails at any step, test template is not correct. Consistency checkes are handled by Orrery itself while loading tests from presets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "315452b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83a58730",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATOR = \"CTT\"\n",
    "VERSION = \"v1\"\n",
    "INPUT_PATH = f\"../data/templates/{GENERATOR}-{VERSION}\".lower()\n",
    "OUTPUT_PATH = \"../data/presets\"\n",
    "DRY = False # don't write files\n",
    "ALL = False # regenerate all\n",
    "\n",
    "\n",
    "class Dumper(yaml.Dumper):\n",
    "    def increase_indent(self, flow=False, indentless=False):\n",
    "        return super(Dumper, self).increase_indent(flow, False)\n",
    "\n",
    "    \n",
    "    \n",
    "def make_header(template: str) -> str:\n",
    "    res = [\n",
    "        '# generated, try not to edit',\n",
    "        f'# by: {GENERATOR}-{VERSION}',\n",
    "        f'# at: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}',\n",
    "        f'# template: {template}',\n",
    "    ]\n",
    "    return \"\\n\".join(res)\n",
    "\n",
    "\n",
    "def generate_presets(input_path: str, output_path: str, dry_run=True, regen_all=False):\n",
    "    templates = [f for f in listdir(INPUT_PATH) if isfile(join(INPUT_PATH, f))]\n",
    "    print(\"found\", len(templates), \"templates\")\n",
    "    for template in templates:\n",
    "        regen = \"yes\"\n",
    "        if not regen_all:\n",
    "            regen = input(f\"Processing {template}. Gerenerate? [yes|NO]\")\n",
    "            \n",
    "        if regen != \"yes\":\n",
    "            print(\"skipping...\")\n",
    "            continue\n",
    "            \n",
    "        publish = \"yes\"\n",
    "        if not regen_all:\n",
    "            publish = input(f\"Processing {template}. Publish? [yes|NO]\")\n",
    "\n",
    "        with open(join(INPUT_PATH, template), 'r') as stream:\n",
    "            test = yaml.safe_load(stream)\n",
    "            \n",
    "        test[\"publish\"] = publish == \"yes\"\n",
    "            \n",
    "        body = make_preset(test)\n",
    "        data = \"\\n\".join([make_header(join(INPUT_PATH, template)), body])\n",
    "        \n",
    "        if not dry_run:\n",
    "            filename = join(output_path, f'test.{test[\"code\"]}.yaml')\n",
    "            with open(filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(data)\n",
    "            print(\"saved to file:\", filename)\n",
    "        else:\n",
    "            print(\"DRY RUN; generated following sweet yaml:\\n\", \"-\"*3, data, \"-\"*3, sep = '\\n')\n",
    "            \n",
    "        print(\"processing template done:\", template)\n",
    "      \n",
    "    \n",
    "def scale_code(t, raw_scale_code):\n",
    "    codes = list(t[\"scales\"].keys())\n",
    "    code = raw_scale_code.strip(\"-\")\n",
    "    number = codes.index(code) + 1\n",
    "    return f'{t[\"code\"]}-{number:02d}-{code}'\n",
    "\n",
    "\n",
    "def make_display(t):\n",
    "    return {\n",
    "        \"questionsPerPage\": t[\"question\"][\"page\"],\n",
    "        \"randomizeOrder\": t[\"randomize\"],\n",
    "    }\n",
    "\n",
    "\n",
    "def make_interpretations(t, scale):\n",
    "    ranges = []\n",
    "    if t[\"type\"] == \"sten\":\n",
    "        for i in range(t[\"intervals\"]):\n",
    "            ranges.append([9/(t[\"intervals\"])*(i)+1, 9/(t[\"intervals\"])*(i+1)+1])\n",
    "    elif t[\"type\"] == \"perc\":\n",
    "        for i in range(t[\"intervals\"]):\n",
    "            ranges.append([100/(t[\"intervals\"])*(i), 100/(t[\"intervals\"])*(i+1)])\n",
    "    else:\n",
    "        print(\"INTERVALS GENERATION IS NOT DEFINED FOR TYPE\", t[\"type\"], \"!!!\")\n",
    "        raise\n",
    "\n",
    "    return [\n",
    "        {\n",
    "            \"range\": ranges[i],\n",
    "            \"translations\": [\n",
    "                {\n",
    "                    \"locale\": loc,\n",
    "                    \"content\": scale[\"interpretations\"][i][loc]\n",
    "                } for loc in t[\"locales\"]\n",
    "            ]\n",
    "        } for i in range(len(ranges))\n",
    "    ]\n",
    "    \n",
    "\n",
    "def make_scales(t):\n",
    "    return [\n",
    "        {\n",
    "            \"code\": scale_code(t, code),\n",
    "            \"type\": t[\"type\"],\n",
    "            \"translations\": [\n",
    "                {\n",
    "                    \"locale\": loc,\n",
    "                    \"title\": s[loc][0],\n",
    "                    \"description\": s[loc][1],\n",
    "                    \"abbreviation\": s[loc][2],\n",
    "                } for loc in t[\"locales\"]\n",
    "            ],\n",
    "            \"interpretations\": make_interpretations(t, s)\n",
    "        } for code, s in t[\"scales\"].items()\n",
    "    ]\n",
    "\n",
    "\n",
    "def make_items(t, scales):\n",
    "    item_codes = []\n",
    "    item_map = { s[\"code\"]:[] for s in scales}\n",
    "    item_counter = Counter()\n",
    "    for i, item in enumerate(t[\"items\"]):\n",
    "        sc = scale_code(t, item[\"scale\"])\n",
    "        item_counter.update([sc])\n",
    "        item_code = f'{sc}-{item_counter[sc]:03d}'\n",
    "        item_map[sc].append({\n",
    "            \"code\": item_code,\n",
    "            \"steps\": t[\"steps\"],\n",
    "            \"reverse\": item[\"scale\"][0] == \"-\",\n",
    "            \"translations\": [\n",
    "                {\n",
    "                    \"locale\": loc,\n",
    "                    \"content\": item[loc],\n",
    "                } for loc in t[\"locales\"]\n",
    "            ]\n",
    "        })\n",
    "        item_codes.append(item_code)\n",
    "    return (item_map, item_codes)\n",
    "\n",
    "\n",
    "def make_test_translations(t):\n",
    "    return [\n",
    "        {\n",
    "            \"locale\": loc,\n",
    "            \"title\": t[loc][0],\n",
    "            \"description\": t[loc][1],\n",
    "            \"instruction\": t[loc][2],\n",
    "            \"details\": t[loc][3],\n",
    "            \"preambule\": t[loc][4],\n",
    "        } for loc in t[\"locales\"]\n",
    "    ]\n",
    "\n",
    "\n",
    "def make_preset(t):\n",
    "    scales = make_scales(t)\n",
    "\n",
    "    item_map, item_codes = make_items(t, scales)   \n",
    "\n",
    "    questions = [\n",
    "        {\n",
    "            \"code\": f'{t[\"code\"]}-{i+1:03d}',\n",
    "            \"order\": (i+1)*10,\n",
    "            \"type\": \"simple\",\n",
    "            \"items\": [{ \"code\":code for code in [c] }],\n",
    "            \"translations\": [\n",
    "                {\n",
    "                    \"locale\": loc,\n",
    "                    \"content\": t[\"question\"][loc],\n",
    "                } for loc in t[\"locales\"]\n",
    "            ],\n",
    "        } for i, c in enumerate(item_codes)\n",
    "    ]\n",
    "\n",
    "    result = {\n",
    "        \"code\": t[\"code\"],\n",
    "        \"published\": t[\"publish\"],\n",
    "        \"availableLocales\": t[\"locales\"],\n",
    "        \"tags\": t[\"tags\"],\n",
    "        \"forceUpdate\": True,\n",
    "        \"translations\": make_test_translations(t),\n",
    "        \"scales\": [{**s, \"items\": item_map[s[\"code\"]]} for s in scales],\n",
    "        \"questions\": questions,\n",
    "        \"display\": make_display(t),\n",
    "    }\n",
    "    \n",
    "    return yaml.dump(result, sort_keys=False, allow_unicode=True, Dumper=Dumper, default_flow_style=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4411d838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 7 templates\n",
      "Processing hexaco.yaml. Gerenerate? [yes|NO]\n",
      "skipping...\n",
      "Processing tipi.yaml. Gerenerate? [yes|NO]\n",
      "skipping...\n",
      "Processing riasec-personality-wisc.yaml. Gerenerate? [yes|NO]\n",
      "skipping...\n",
      "Processing political-compass.yaml. Gerenerate? [yes|NO]yes\n",
      "Processing political-compass.yaml. Publish? [yes|NO]yes\n",
      "saved to file: ../data/presets/test.political-compass.yaml\n",
      "processing template done: political-compass.yaml\n",
      "Processing riasec-combined-wisc.yaml. Gerenerate? [yes|NO]\n",
      "skipping...\n",
      "Processing riasec-activity-wisc.yaml. Gerenerate? [yes|NO]\n",
      "skipping...\n",
      "Processing fipi.yaml. Gerenerate? [yes|NO]\n",
      "skipping...\n",
      "CPU times: user 145 ms, sys: 14.1 ms, total: 159 ms\n",
      "Wall time: 8.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "generate_presets(INPUT_PATH, OUTPUT_PATH, DRY, ALL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
